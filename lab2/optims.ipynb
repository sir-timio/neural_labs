{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a231363",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4d4ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD():\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def init_params(self, model):\n",
    "        self.model = model\n",
    "        self.layers = [l  for l in model.layers if type(l) == Linear]\n",
    "\n",
    "    def step(self):\n",
    "        for layer in self.layers:\n",
    "            layer.w -= self.lr * layer.grad_w\n",
    "            layer.b -= self.lr * layer.grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f555d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Momentum():\n",
    "    def __init__(self, lr=0.01, momentum=0.6):\n",
    "        self.m = momentum\n",
    "        self.lr = lr\n",
    "    \n",
    "    def init_params(self, model):\n",
    "        self.model = model\n",
    "        self.layers = [l  for l in model.layers if type(l) == Linear]\n",
    "        \n",
    "        self.velocity_w = []\n",
    "        self.velocity_b = []\n",
    "        for l in self.layers:\n",
    "            self.velocity_w.append(np.zeros_like(l.w))\n",
    "            self.velocity_b.append(np.zeros_like(l.b))\n",
    "   \n",
    "    def step(self):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            self.velocity_w[i] = self.m * self.velocity_w[i] + self.lr * layer.grad_w\n",
    "            self.velocity_b[i] = self.m * self.velocity_b[i] + self.lr * layer.grad_b\n",
    "            layer.w -= self.velocity_w[i]\n",
    "            layer.b -= self.velocity_b[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ce85c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nesterov():\n",
    "    def __init__(self, lr=0.01, momentum=0.6):\n",
    "        self.m = momentum\n",
    "        self.lr = lr\n",
    "    \n",
    "    def init_params(self, model):\n",
    "        self.model = model\n",
    "        self.layers = [l  for l in model.layers if type(l) == Linear]\n",
    "        \n",
    "        self.velocity_w = []\n",
    "        self.velocity_b = []\n",
    "        for l in self.layers:\n",
    "            self.velocity_w.append(np.zeros_like(l.w))\n",
    "            self.velocity_b.append(np.zeros_like(l.b))\n",
    "        \n",
    "    def step(self):\n",
    "        model_ahead =  deepcopy(model)\n",
    "        ahead_layers = [l  for l in model_ahead.layers if type(l) == Linear]\n",
    "        \n",
    "        for i, layer in enumerate(ahead_layers):\n",
    "            layer.w -= self.m * self.velocity_w[i] \n",
    "            layer.b -= self.m * self.velocity_b[i]\n",
    "        \n",
    "        \n",
    "        model_ahead.loss(self.model.cur_x, self.model.cur_y)\n",
    "        model_ahead.backward()\n",
    "        \n",
    "        ahead_layers = [l  for l in model_ahead.layers if type(l) == Linear]\n",
    "        \n",
    "        for i, t in enumerate(zip(ahead_layers, self.layers)):\n",
    "            ahead_layer, layer = t\n",
    "            \n",
    "            self.velocity_w[i] = self.m * self.velocity_w[i] + self.lr * ahead_layer.grad_w\n",
    "            self.velocity_b[i] = self.m * self.velocity_b[i] + self.lr * ahead_layer.grad_b\n",
    "            \n",
    "            layer.w -= self.velocity_w[i]\n",
    "            layer.b -= self.velocity_b[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d3ba118",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad():\n",
    "    def __init__(self, lr=1):\n",
    "        self.lr = lr\n",
    "        self.eps = 1e-10\n",
    "\n",
    "    \n",
    "    def init_params(self, model):\n",
    "        self.model = model\n",
    "        self.layers = [l  for l in model.layers if type(l) == Linear]\n",
    "        \n",
    "        self.N_w = []\n",
    "        self.N_b = []\n",
    "        for l in self.layers:\n",
    "            self.N_w.append(np.zeros_like(l.w))\n",
    "            self.N_b.append(np.zeros_like(l.b))\n",
    "   \n",
    "    def step(self):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            \n",
    "            self.N_w[i] += layer.grad_w ** 2 \n",
    "            self.N_b[i] += layer.grad_b ** 2\n",
    "            \n",
    "            layer.w -= self.lr * layer.grad_w / (np.sqrt(self.N_w[i]) + self.eps)\n",
    "            layer.b -= self.lr * layer.grad_b / (np.sqrt(self.N_b[i]) + self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09514e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSprop():\n",
    "    def __init__(self, lr=0.01, decay=0.9):\n",
    "        self.lr = lr\n",
    "        self.decay = decay\n",
    "        self.eps = 1e-10\n",
    "    \n",
    "    def init_params(self, model):\n",
    "        self.model = model\n",
    "        self.layers = [l  for l in model.layers if type(l) == Linear]\n",
    "        \n",
    "        self.N_w = []\n",
    "        self.N_b = []\n",
    "        for l in self.layers:\n",
    "            self.N_w.append(np.zeros_like(l.w))\n",
    "            self.N_b.append(np.zeros_like(l.b))\n",
    "   \n",
    "    def step(self):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            \n",
    "            self.N_w[i] = self.decay * self.N_w[i] + (1-self.decay) * layer.grad_w ** 2\n",
    "            self.N_b[i] = self.decay * self.N_b[i] + (1-self.decay) * layer.grad_b ** 2\n",
    "            \n",
    "            layer.w -= self.lr * layer.grad_w / (np.sqrt(self.N_w[i]) + self.eps)\n",
    "            layer.b -= self.lr * layer.grad_b / (np.sqrt(self.N_b[i]) + self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c43348d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaDelta():\n",
    "    def __init__(self, lr=0.01, decay=0.9):\n",
    "        self.lr = lr\n",
    "        self.decay = decay\n",
    "        self.eps = 1e-10\n",
    "    \n",
    "    def init_params(self, model):\n",
    "        self.model = model\n",
    "        self.layers = [l  for l in model.layers if type(l) == Linear]\n",
    "        \n",
    "        self.N_w = []\n",
    "        self.N_b = []\n",
    "        \n",
    "        self.P_w = []\n",
    "        self.P_b = []\n",
    "        for l in self.layers:\n",
    "            self.N_w.append(np.zeros_like(l.w))\n",
    "            self.N_b.append(np.zeros_like(l.b))\n",
    "            \n",
    "            self.P_w.append(np.zeros_like(l.w))\n",
    "            self.P_b.append(np.zeros_like(l.b))\n",
    "            \n",
    "\n",
    "    def step(self):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            self.N_w[i] = self.decay * self.N_w[i] + (1-self.decay)*layer.grad_w ** 2 \n",
    "            self.N_b[i] = self.decay * self.N_b[i] + (1-self.decay)*layer.grad_b ** 2\n",
    "\n",
    "            d_w = layer.grad_w * np.sqrt(self.P_w[i] + self.eps) / np.sqrt(self.N_w[i] + self.eps)\n",
    "            d_b = layer.grad_b * np.sqrt(self.P_b[i] + self.eps) / np.sqrt(self.N_b[i] + self.eps)\n",
    "\n",
    "            self.P_w[i] = self.decay * self.P_w[i] + (1 - self.decay) * d_w ** 2\n",
    "            self.P_b[i] = self.decay * self.P_b[i] + (1 - self.decay) * d_b ** 2\n",
    "            layer.w -= self.lr * d_w\n",
    "            layer.b -= self.lr * d_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5f2251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam():\n",
    "    def __init__(self, lr=0.01, beta1=0.9, beta2=0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = 1e-10\n",
    "    \n",
    "    def init_params(self, model):\n",
    "        self.model = model\n",
    "        self.layers = [l  for l in model.layers if type(l) == Linear]\n",
    "                \n",
    "        self.M_w = []\n",
    "        self.M_b = []\n",
    "        \n",
    "        self.N_w = []\n",
    "        self.N_b = []\n",
    "        for l in self.layers:              \n",
    "            self.M_w.append(np.zeros_like(l.w))\n",
    "            self.M_b.append(np.zeros_like(l.b))\n",
    "            \n",
    "            self.N_w.append(np.zeros_like(l.w))\n",
    "            self.N_b.append(np.zeros_like(l.b))\n",
    "            \n",
    "   \n",
    "    def step(self):\n",
    "        t = self.model.cur_epoch + 1\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            self.M_w[i] = self.beta1 * self.M_w[i] + (1 - self.beta1) * layer.grad_w\n",
    "            self.M_b[i] = self.beta1 * self.M_b[i] + (1 - self.beta1) * layer.grad_b\n",
    "\n",
    "\n",
    "            self.N_w[i] = self.beta2 * self.N_w[i] + (1 - self.beta2) * layer.grad_w ** 2\n",
    "            self.N_b[i] = self.beta2 * self.N_b[i] + (1 - self.beta2) * layer.grad_b ** 2\n",
    "            \n",
    "            m_w_hat = self.M_w[i] / (1 - self.beta1 ** t)\n",
    "            m_b_hat = self.M_b[i] / (1 - self.beta1 ** t)\n",
    "            \n",
    "            n_w_hat = self.N_w[i] / (1 - self.beta2 ** t)\n",
    "            n_b_hat = self.N_b[i] / (1 - self.beta2 ** t)\n",
    "\n",
    "\n",
    "            layer.w -= self.lr * m_w_hat / (np.sqrt(n_w_hat) + self.eps)\n",
    "            layer.b -= self.lr * m_b_hat / (np.sqrt(n_b_hat) + self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69164f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
